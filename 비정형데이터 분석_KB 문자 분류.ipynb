{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/train.csv')\n",
    "train.head()\n",
    "test = pd.read_csv('/kaggle/public_test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 사용 \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "\n",
    "# train과 test 모든 'text' 데이터 숫자화 \n",
    "tk.fit_on_texts(list(train['text']) + list(test['text']))\n",
    "\n",
    "\n",
    "tk.word_index \n",
    "len(tk.word_index) \n",
    "\n",
    "# 각 데이터 프레임 내 텍스트를 숫자화\n",
    "train_text = tk.texts_to_sequences(train['text'])\n",
    "test_text = tk.texts_to_sequences(test['text'])\n",
    "\n",
    "\n",
    "pd.Series(train_text).apply(lambda x : len(x)).max()\n",
    "pd.Series(train_text).apply(len)\n",
    "\n",
    "\n",
    "# 숫자로 변한 텍스트의 분포 확인\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "a, b = plt.subplots(1,1,figsize=(20,12)) # 밑그림\n",
    "sns.distplot(pd.Series(train_text).apply(len)) # 대다수가 50개 정도 / train을 보면 test도 봐야함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 근데 위 빈도 그래프에 따라서 100개에서 짤라도 크게 차이는 없을 것 같음 \n",
    "pad_train = pad_sequences(train_text, maxlen=100, truncating ='post', padding= 'post') # truncating 기본 값은 pre\n",
    "pad_test = pad_sequences(test_text, maxlen=100, truncating ='post', padding= 'post') # truncating 기본 값은 pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스미싱이 전체 데이터 셋과 비교해 6%를 차지\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(pad_train, train['smishing'], test_size = 0.15, random_state=0, stratify=train['smishing']) #stratify 0,1 비율을 자동으로 맞춰줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Embedding, Flatten \n",
    "\n",
    "# 2) 모델쌓기, 선언\n",
    "model = Sequential()\n",
    "model.add(Embedding(448903,25,input_length=100)) #  열심히 찾아나가야 되는 부분\n",
    "\n",
    "#embedding(단어의 의미를 학습한다), 각 데이터에 접근해 스미싱인가 아닌가 *단어*를 보고 판단해야함 \n",
    "\n",
    "model.add(Flatten()) # 2차원 -> 1차원 \n",
    "model.add(Dense(2, activation='softmax')) # 옵션2개 중 1개는 정답 클래스 갯수\n",
    "\n",
    "model.compile(metrics = ['acc'], optimizer = 'adam', loss='sparse_categorical_crossentropy') # 3가지 옵션 넣어줄거임 * compile, 모델선언 완료\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es = EarlyStopping(patience=2) \n",
    "mc = ModelCheckpoint('best.h5', save_best_only=True) \n",
    "\n",
    "# 3) 모델 학습\n",
    "# model.fit(x_train, y_train, epochs=100, validation_split=0.1,batch_size=128, callbacks=[es,mc]) #callback #batch size는 32가 기본 / \n",
    "# x, y 설정 / 학습 횟수 결정, epoch / 학습(90%), 평가(10%)\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid),batch_size=128, callbacks=[es,mc]) #callback #batch size는 32가 기본 /  \n",
    "# x, y 설정 / 학습 횟수 결정, epoch / 학습(90%), 평가(10%)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 가중치 저장된 걸 가져와야함 \n",
    "model.load_weights('best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "result = model.predict(pad_test, batch_size=128) #pad_test는 뒤쪽 짜른거 \n",
    "result\n",
    "# 왼쪽 / 오른쪽(), 스미싱 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['smishing'] = result[:,1]\n",
    "sub = test[['id','smishing']]\n",
    "sub.to_csv('baseline_평가셋 수정.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.read_csv('/kaggle/output/working/baseline_평가셋 수정.csv')\n",
    "second = pd.read_csv('/kaggle/input/taling/baseline_ .csv')\n",
    "display(first.head())\n",
    "display(second.head()) # 비교 시, 스미싱을 판단하는 수치 다름\n",
    "# roc-auc평가방식 -> 확률이 중요한게 아닌, 상대적 순위가 중요해짐. 이에 두개의 앙상블 시, '순위'를 고려해야함 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
